{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 9\n",
    "\n",
    "## ASTR 5900, Fall 2017, University of Oklahoma\n",
    "\n",
    "### Principal Components Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "Load the iris data, which is a classic data set often used in machine learning examples.  It can be accessed via `sklearn` by calling `sklearn.datasets.load_iris`.  This returns an object whose attributes is what we are after: `object.data` is the data, `object.target` is the labels.\n",
    "\n",
    "You will want to understand what these numbers mean. You should read up on the iris data here: https://archive.ics.uci.edu/ml/datasets/iris\n",
    "\n",
    "Perform PCA from scratch on this data.  Print the principal components and the corresponding eigenvalues.  Determine the fraction of the variance contributed by each eigenvector.\n",
    "\n",
    "Determine the 2 \"most important\" correlations and project the original data onto these components.  Plot the results using `matplotlib.pyplot`.  Color the new data points based on their target labels.\n",
    "\n",
    "When you are done, answer the discussion prompt below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Comment on your results.  Interpret the principal components.  Remember the PCA did not use the target labels in its calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "You are to use `empca` on spectral data as in the lecture.  Information can be found here: https://github.com/sbailey/empca.  You can download the module from the same link.  In order to import `empca`, `empca.py` must be listed in your PYTHONPATH or located in the directory you are working in.\n",
    "\n",
    "The data can be accessed in the class GitHub repository in `/data/quasar/`.  There are 3 .npy files containing the spectral data, data weights, and sampled wavelengths.  Each can be loaded by calling `numpy.load`.\n",
    "\n",
    "The data containes fluxes and weights for 480 SDSS quasar spectra.\n",
    "The data is already normalized; they were normalized by\n",
    "dividing by the flux in an emission-line-free band near 1700\n",
    "angstroms.  A power law model was used to subtract the continuum from\n",
    "the accretion disk, leaving behind the emission line spectrum.  Thus,\n",
    "you do not have to normalize them, but you do have to do the rest of\n",
    "the analysis, e.g., detminining the weighed mean spectrum and\n",
    "subtracting it.\n",
    "\n",
    "### Part A\n",
    "\n",
    "Load the data then subtract the weighted mean from each object.  Plot the mean data of each wavelength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "Run `empca.empca` on the now subtracted data.  Construct a model with 25 components.  \n",
    "\n",
    "Print the fraction of variance attributed to each eigenvector.\n",
    "\n",
    "Plot the first 4 eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "Plot the 400th object in the data (index = 400, not 399).  \"Reconstruct\" this object by summing contributions from the first few principal components with the mean calculated in part A.  In other words: plot the mean over the 400th object, then plot the mean plus the contribution from the 1st principal component over the object, and so on.  Do this for the first 4 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Z\n",
    "\n",
    "Comment on the time this assignment required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
